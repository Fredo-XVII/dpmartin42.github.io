<!DOCTYPE html>
<html lang="en-us">

<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    Handling Class Imbalance with R and Caret - An Introduction | Wicked Good Data
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0d sidebar-overlay">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    
    <center>
    <img style="max-height: 200px; height: 80%; width: 80%; border-radius: 50%" src="/extras/DanielPMartin.jpeg" align="middle"></a></img>
    </center>
    
    <p>Quantitative Psychology PhD and Data Scientist at McKinsey & Company.</p>
    
    <p>
    
    <div style = "font-size: 30px">
    
    <script>
      emailE = ('dpmartin42@' + 'gmail.com')
	  document.write('<a href="mailto:' + emailE + '"><i class="fa fa-envelope-square"></i></a>')
	</script>
    
    <a href="https://github.com/dpmartin42"><i class="fa fa-github"></i></a>
    
    <a href="http://stackexchange.com/users/2457894/dmartin?tab=accounts"><i class="fa fa-stack-exchange"></i></a>
    
    <a href="http://linkedin.com/in/dpmartin42/"><i class="fa fa-linkedin"></i></a>
    
    </div>
    
  </div>
  

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about.html">About Me</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/blog_roll.html">Blog Roll</a>
        
      
    
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/posts.html">Posts</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/visualizations.html">Visualizations</a>
        
      
    

  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2016. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Wicked Good Data</a>
            <small>Website and blog of Daniel P. Martin</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h2 class="post-title">Handling Class Imbalance with R and Caret - An Introduction</h2>
  <span class="post-date">December 10, 2016</span>
  <p>When faced with classification tasks in the real world, it can be challenging to deal with an outcome where one class heavily outweighs the other (a.k.a., imbalanced classes). The following will be a two-part post on some of the techniques that can help to improve prediction performance in the case of imbalanced classes using R and caret. This first post provides a general overview of how these techniques can be implemented in practice, and the second post highlights some caveats to keep in mind when using these methods.</p>

<h2 id="evaluation-metrics-for-classifiers">Evaluation metrics for classifiers</h2>

<p>After building a classifier, you need to decide how to tell if it is doing a good job or not. Many evaluation metrics for classifiers exist, and can generally be divided into two main groups:</p>

<ol>
  <li>
    <p>Threshold-dependent: This includes metrics like accuracy, precision, recall, and F1 score, which all require a confusion matrix to be calculated using a hard cutoff on predicted probabilities. These metrics are typically quite poor in the case of imbalanced classes, as statistical software inappropriately uses a default threshold of 0.50 resulting in the model predicting that all observations belong in the majority class.</p>
  </li>
  <li>
    <p>Threshold-invariant: This includes metrics like area under the ROC curve (AUC), which quantifies true positive rate as a function of false positive rate for a variety of classification thresholds. Another way to interpret this metric is the probability that a random positive instance will have a higher estimated probability than a random negative instance.</p>
  </li>
</ol>

<h2 id="methods-to-improve-performance-on-imbalanced-data">Methods to improve performance on imbalanced data</h2>

<p>A few of the more popular techniques to deal with class imbalance will be covered below, but the following list is nowhere near exhaustive. For brevity, a quick overview is provided. For a more substantial overview, I highly recommend this <a href="https://svds.com/learning-imbalanced-classes/">Silicon Valley Data Science blog post</a>.</p>

<ul>
  <li>
    <p>Class weights: impose a heavier cost when errors are made in the minority class</p>
  </li>
  <li>
    <p>Down-sampling: randomly remove instances in the majority class</p>
  </li>
  <li>
    <p>Up-sampling: randomly replicate instances in the minority class</p>
  </li>
  <li>
    <p>Synthetic minority sampling technique (SMOTE): down samples the majority class and synthesizes new minority instances by interpolating between existing ones</p>
  </li>
</ul>

<p>It is important to note that these weighting and sampling techniques have the biggest impact on threshold-dependent metrics like accuracy, because they artificially move the threshold to be closer to what might be considered as the “optimal” location on a ROC curve. Threshold-invariant metrics can still be improved using these methods, but the effect will not be as pronounced.</p>

<h2 id="simulation-set-up">Simulation set-up</h2>

<p>To simulate class imbalance, the <code>twoClassSim</code> function from caret is used. Here, we simulate a separate training set and test set, each with 5000 observations. Additionally, we include 20 meaningful variables and 10 noise variables. The intercept argument controls the overall level of class imbalance and has been selected to yield a class imbalance of around 50:1.</p>

<div class="highlight"><pre><code class="language-r" data-lang="r"><span class="kn">library</span><span class="p">(</span>dplyr<span class="p">)</span> <span class="c1"># for data manipulation</span>
<span class="kn">library</span><span class="p">(</span>caret<span class="p">)</span> <span class="c1"># for model-building</span>
<span class="kn">library</span><span class="p">(</span>DMwR<span class="p">)</span> <span class="c1"># for smote implementation</span>
<span class="kn">library</span><span class="p">(</span>purrr<span class="p">)</span> <span class="c1"># for functional programming (map)</span>
<span class="kn">library</span><span class="p">(</span>pROC<span class="p">)</span> <span class="c1"># for AUC calculations</span>

<span class="kp">set.seed</span><span class="p">(</span><span class="m">2969</span><span class="p">)</span>

imbal_train <span class="o">&lt;-</span> twoClassSim<span class="p">(</span><span class="m">5000</span><span class="p">,</span>
                           intercept <span class="o">=</span> <span class="m">-25</span><span class="p">,</span>
                           linearVars <span class="o">=</span> <span class="m">20</span><span class="p">,</span>
                           noiseVars <span class="o">=</span> <span class="m">10</span><span class="p">)</span>

imbal_test  <span class="o">&lt;-</span> twoClassSim<span class="p">(</span><span class="m">5000</span><span class="p">,</span>
                           intercept <span class="o">=</span> <span class="m">-25</span><span class="p">,</span>
                           linearVars <span class="o">=</span> <span class="m">20</span><span class="p">,</span>
                           noiseVars <span class="o">=</span> <span class="m">10</span><span class="p">)</span>
  
<span class="kp">prop.table</span><span class="p">(</span><span class="kp">table</span><span class="p">(</span>imbal_train<span class="o">$</span>Class<span class="p">))</span></code></pre></div>

<div class="highlight"><pre><code class="language-text" data-lang="text">## 
## Class1 Class2 
## 0.9796 0.0204</code></pre></div>

<h2 id="initial-results">Initial results</h2>

<p>To model these data, a gradient boosting machine (gbm) is used as it can easily handle potential interactions and non-linearities that have been simulated above. Model hyperparameters are tuned using repeated cross-validation on the training set, repeating five times with ten folds used in each repeat. The AUC is used to evaluate the classifier to avoid having to make decisions about the classification threshold. Note that this code takes a little while to run due to the repeated cross-validation, so reduce the number of repeats to speed things up and/or use the <code>verboseIter = TRUE</code> argument in the <code>trainControl</code> function to keep track of the progress.</p>

<div class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># Set up control function for training</span>

ctrl <span class="o">&lt;-</span> trainControl<span class="p">(</span>method <span class="o">=</span> <span class="s">&quot;repeatedcv&quot;</span><span class="p">,</span>
                     number <span class="o">=</span> <span class="m">10</span><span class="p">,</span>
                     repeats <span class="o">=</span> <span class="m">5</span><span class="p">,</span>
                     summaryFunction <span class="o">=</span> twoClassSummary<span class="p">,</span>
                     classProbs <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="c1"># Build a standard classifier using a gradient boosted machine</span>

<span class="kp">set.seed</span><span class="p">(</span><span class="m">5627</span><span class="p">)</span>

orig_fit <span class="o">&lt;-</span> train<span class="p">(</span>Class <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
                  data <span class="o">=</span> imbal_train<span class="p">,</span>
                  method <span class="o">=</span> <span class="s">&quot;gbm&quot;</span><span class="p">,</span>
                  verbose <span class="o">=</span> <span class="kc">FALSE</span><span class="p">,</span>
                  metric <span class="o">=</span> <span class="s">&quot;ROC&quot;</span><span class="p">,</span>
                  trControl <span class="o">=</span> ctrl<span class="p">)</span>

<span class="c1"># Build custom AUC function to extract AUC</span>
<span class="c1"># from the caret model object</span>

test_roc <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>model<span class="p">,</span> data<span class="p">)</span> <span class="p">{</span>
  
  roc<span class="p">(</span>data<span class="o">$</span>Class<span class="p">,</span>
      predict<span class="p">(</span>model<span class="p">,</span> data<span class="p">,</span> type <span class="o">=</span> <span class="s">&quot;prob&quot;</span><span class="p">)[,</span> <span class="s">&quot;Class2&quot;</span><span class="p">])</span>

<span class="p">}</span>

orig_fit <span class="o">%&gt;%</span>
  test_roc<span class="p">(</span>data <span class="o">=</span> imbal_test<span class="p">)</span> <span class="o">%&gt;%</span>
  auc<span class="p">()</span></code></pre></div>

<div class="highlight"><pre><code class="language-text" data-lang="text">## Area under the curve: 0.9575</code></pre></div>

<p>Overall, the final model yields an AUC of 0.96 which is quite good. Can we improve it using the techniques outlined above?</p>

<h2 id="handling-class-imbalance-with-weighted-or-sampling-methods">Handling class imbalance with weighted or sampling methods</h2>

<p>Both weighting and sampling methods are easy to employ in caret. Incorporating weights into the model can be handled by using the weights argument in the <code>train</code> function (assuming the model can handle weights in caret, see the list <a href="https://topepo.github.io/caret/train-models-by-tag.html#Accepts_Case_Weights">here</a>), while the sampling methods mentioned above can be implemented using the sampling argument in the <code>trainControl</code> function. Note that the same seeds were used for each model to ensure that results from the same cross-validation folds are being used.</p>

<p>Also keep in mind that for sampling methods, it is vital that you only sample the training set and not the test set as well. This means that when doing cross-validation, the sampling step must be done inside of the cross-validation procedure. Max Kuhn of the caret package gives a good overview of what happens when you don’t take this precaution in <a href="https://topepo.github.io/caret/subsampling-for-class-imbalances.html">this caret documentation</a>. Using the sampling argument in the <code>trainControl</code> function implements sampling correctly in the cross-validation procedure.</p>

<div class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># Create model weights (they sum to one)</span>

model_weights <span class="o">&lt;-</span> <span class="kp">ifelse</span><span class="p">(</span>imbal_train<span class="o">$</span>Class <span class="o">==</span> <span class="s">&quot;Class1&quot;</span><span class="p">,</span>
                        <span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="kp">table</span><span class="p">(</span>imbal_train<span class="o">$</span>Class<span class="p">)[</span><span class="m">1</span><span class="p">])</span> <span class="o">*</span> <span class="m">0.5</span><span class="p">,</span>
                        <span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="kp">table</span><span class="p">(</span>imbal_train<span class="o">$</span>Class<span class="p">)[</span><span class="m">2</span><span class="p">])</span> <span class="o">*</span> <span class="m">0.5</span><span class="p">)</span>

<span class="c1"># Use the same seed to ensure same cross-validation splits</span>

ctrl<span class="o">$</span>seeds <span class="o">&lt;-</span> orig_fit<span class="o">$</span>control<span class="o">$</span>seeds

<span class="c1"># Build weighted model</span>

weighted_fit <span class="o">&lt;-</span> train<span class="p">(</span>Class <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
                      data <span class="o">=</span> imbal_train<span class="p">,</span>
                      method <span class="o">=</span> <span class="s">&quot;gbm&quot;</span><span class="p">,</span>
                      verbose <span class="o">=</span> <span class="kc">FALSE</span><span class="p">,</span>
                      weights <span class="o">=</span> model_weights<span class="p">,</span>
                      metric <span class="o">=</span> <span class="s">&quot;ROC&quot;</span><span class="p">,</span>
                      trControl <span class="o">=</span> ctrl<span class="p">)</span>

<span class="c1"># Build down-sampled model</span>

ctrl<span class="o">$</span>sampling <span class="o">&lt;-</span> <span class="s">&quot;down&quot;</span>

down_fit <span class="o">&lt;-</span> train<span class="p">(</span>Class <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
                  data <span class="o">=</span> imbal_train<span class="p">,</span>
                  method <span class="o">=</span> <span class="s">&quot;gbm&quot;</span><span class="p">,</span>
                  verbose <span class="o">=</span> <span class="kc">FALSE</span><span class="p">,</span>
                  metric <span class="o">=</span> <span class="s">&quot;ROC&quot;</span><span class="p">,</span>
                  trControl <span class="o">=</span> ctrl<span class="p">)</span>

<span class="c1"># Build up-sampled model</span>

ctrl<span class="o">$</span>sampling <span class="o">&lt;-</span> <span class="s">&quot;up&quot;</span>

up_fit <span class="o">&lt;-</span> train<span class="p">(</span>Class <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
                data <span class="o">=</span> imbal_train<span class="p">,</span>
                method <span class="o">=</span> <span class="s">&quot;gbm&quot;</span><span class="p">,</span>
                verbose <span class="o">=</span> <span class="kc">FALSE</span><span class="p">,</span>
                metric <span class="o">=</span> <span class="s">&quot;ROC&quot;</span><span class="p">,</span>
                trControl <span class="o">=</span> ctrl<span class="p">)</span>

<span class="c1"># Build smote model</span>

ctrl<span class="o">$</span>sampling <span class="o">&lt;-</span> <span class="s">&quot;smote&quot;</span>

smote_fit <span class="o">&lt;-</span> train<span class="p">(</span>Class <span class="o">~</span> <span class="m">.</span><span class="p">,</span>
                   data <span class="o">=</span> imbal_train<span class="p">,</span>
                   method <span class="o">=</span> <span class="s">&quot;gbm&quot;</span><span class="p">,</span>
                   verbose <span class="o">=</span> <span class="kc">FALSE</span><span class="p">,</span>
                   metric <span class="o">=</span> <span class="s">&quot;ROC&quot;</span><span class="p">,</span>
                   trControl <span class="o">=</span> ctrl<span class="p">)</span></code></pre></div>

<p>Examining the AUC calculated on the test set shows a clear distinction between the original model implementation and those that incorporated either a weighting or sampling technique. The weighted method possessed the highest AUC value, followed by the sampling methods, with the original model implementation performing the worst.</p>

<div class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># Examine results for test set</span>

model_list <span class="o">&lt;-</span> <span class="kt">list</span><span class="p">(</span>original <span class="o">=</span> orig_fit<span class="p">,</span>
                   weighted <span class="o">=</span> weighted_fit<span class="p">,</span>
                   down <span class="o">=</span> down_fit<span class="p">,</span>
                   up <span class="o">=</span> up_fit<span class="p">,</span>
                   SMOTE <span class="o">=</span> smote_fit<span class="p">)</span>

model_list_roc <span class="o">&lt;-</span> model_list <span class="o">%&gt;%</span>
  map<span class="p">(</span>test_roc<span class="p">,</span> data <span class="o">=</span> imbal_test<span class="p">)</span>

model_list_roc <span class="o">%&gt;%</span>
  map<span class="p">(</span>auc<span class="p">)</span></code></pre></div>

<div class="highlight"><pre><code class="language-text" data-lang="text">## $original
## Area under the curve: 0.9575
## 
## $weighted
## Area under the curve: 0.9804
## 
## $down
## Area under the curve: 0.9705
## 
## $up
## Area under the curve: 0.9759
## 
## $SMOTE
## Area under the curve: 0.976</code></pre></div>

<p>We can examine the actual ROC curve to get a better idea of where the weighted and sampling models are outperforming the original model at a variety of classification thresholds. Here, we see that the weighted model seems to dominate the others throughout, while the original model lags between a false positive rate between 0% and 25%. This indicates that the other models have better early retrieval numbers. That is, the algorithm better identifies the true positives as a function of false positives for instances that are predicted as having a high probability of being in the minority class.</p>

<div class="highlight"><pre><code class="language-r" data-lang="r">results_list_roc <span class="o">&lt;-</span> <span class="kt">list</span><span class="p">(</span><span class="kc">NA</span><span class="p">)</span>
num_mod <span class="o">&lt;-</span> <span class="m">1</span>

<span class="kr">for</span><span class="p">(</span>the_roc <span class="kr">in</span> model_list_roc<span class="p">){</span>
  
  results_list_roc<span class="p">[[</span>num_mod<span class="p">]]</span> <span class="o">&lt;-</span> 
    <span class="kt">data_frame</span><span class="p">(</span>tpr <span class="o">=</span> the_roc<span class="o">$</span>sensitivities<span class="p">,</span>
               fpr <span class="o">=</span> <span class="m">1</span> <span class="o">-</span> the_roc<span class="o">$</span>specificities<span class="p">,</span>
               model <span class="o">=</span> <span class="kp">names</span><span class="p">(</span>model_list<span class="p">)[</span>num_mod<span class="p">])</span>
  
  num_mod <span class="o">&lt;-</span> num_mod <span class="o">+</span> <span class="m">1</span>
  
<span class="p">}</span>

results_df_roc <span class="o">&lt;-</span> bind_rows<span class="p">(</span>results_list_roc<span class="p">)</span>

<span class="c1"># Plot ROC curve for all 5 models</span>

custom_col <span class="o">&lt;-</span> <span class="kt">c</span><span class="p">(</span><span class="s">&quot;#000000&quot;</span><span class="p">,</span> <span class="s">&quot;#009E73&quot;</span><span class="p">,</span> <span class="s">&quot;#0072B2&quot;</span><span class="p">,</span> <span class="s">&quot;#D55E00&quot;</span><span class="p">,</span> <span class="s">&quot;#CC79A7&quot;</span><span class="p">)</span>

ggplot<span class="p">(</span>aes<span class="p">(</span>x <span class="o">=</span> fpr<span class="p">,</span>  y <span class="o">=</span> tpr<span class="p">,</span> group <span class="o">=</span> model<span class="p">),</span> data <span class="o">=</span> results_df_roc<span class="p">)</span> <span class="o">+</span>
  geom_line<span class="p">(</span>aes<span class="p">(</span>color <span class="o">=</span> model<span class="p">),</span> size <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">+</span>
  scale_color_manual<span class="p">(</span>values <span class="o">=</span> custom_col<span class="p">)</span> <span class="o">+</span>
  geom_abline<span class="p">(</span>intercept <span class="o">=</span> <span class="m">0</span><span class="p">,</span> slope <span class="o">=</span> <span class="m">1</span><span class="p">,</span> color <span class="o">=</span> <span class="s">&quot;gray&quot;</span><span class="p">,</span> size <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">+</span>
  theme_bw<span class="p">(</span>base_size <span class="o">=</span> <span class="m">18</span><span class="p">)</span></code></pre></div>

<p><img src="/figs/2016-12-10-imbalanced-classes-part-1/unnamed-chunk-5-1.png" alt="center" /></p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>In the above post, I outline some steps to help improve classification performance when you have imbalanced classes. Although weighting outperformed the sampling techniques in this simulation, this may not always be the case. Because of this, it is important to compare different techniques to see which works best for your data. I have actually found that in many cases, there is no huge benefit in using either weighting or sampling techniques when classes are moderately imbalanced (i.e., no worse than 10:1) in conjunction with a threshold-invariant metric like the AUC. In the next post, I will go over some caveats to keep in mind when using the AUC in the case of imbalanced classes and how other metrics can be more informative. Stay tuned!</p>


</div>

<div class="related">
  <h2>About</h2>

      <p>
        I am a data scientist for Organizational Solutions at McKinsey & Company, interested in
        statistics, data mining/machine learning, education, and open science, among other things. 
        All opinions and views expressed on this blog are my own and do not represent my employer. 
      </p>
      
          <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'dpmartin42githubio'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53291521-1', 'auto');
  ga('send', 'pageview');

</script>  
    
  </body>
</html>
